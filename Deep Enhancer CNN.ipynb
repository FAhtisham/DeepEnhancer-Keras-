{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Drzeeshan.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59YsDJ6HBIoI",
        "colab_type": "text"
      },
      "source": [
        "# Importing libraries "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-XmKHr9ONEH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import BatchNormalization \n",
        "from tensorflow.keras import activations \n",
        "from tensorflow.keras.layers import MaxPool1D, MaxPool2D, Activation, Conv1D, InputLayer, Conv2D, Dense, Dropout, Flatten,MaxPooling2D\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow import keras\n",
        "import re"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jcQQoXNmBPKn",
        "colab_type": "text"
      },
      "source": [
        "# Generation of DNA Sequences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UnAYHP2hONEL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seq_length = 200\n",
        "motif_length = 20\n",
        "temp_bp = ' '\n",
        "\n",
        "sequences_char = list()\n",
        "\n",
        "# Generating random sequences of length  200\n",
        "for i in range(2500):\n",
        "    sequence_char = np.array([])\n",
        "\n",
        "    \n",
        "    for j in range(765):\n",
        "        num = random.randint(0, 255)\n",
        "        if num <64:\n",
        "            temp_bp = 'A'\n",
        "        elif num < 128 and num >= 64:\n",
        "            temp_bp = 'T'\n",
        "        elif num < 192 and num >= 128:\n",
        "            temp_bp = 'C'\n",
        "        elif num <255 and num >=192:\n",
        "            temp_bp = 'G'\n",
        "            \n",
        "        sequence_char = np.hstack((sequence_char,temp_bp))\n",
        "\n",
        "        \n",
        "    sequences_char.append(sequence_char)\n",
        "\n",
        "    \n",
        "    \n",
        "sequences_str=list()\n",
        "sequences_str2=list()\n",
        "motif =    \"ATCGATCGATCGATCGATC\"\n",
        "enhancer = \"AAAAAAAAAAAAAAAAAAA\"\n",
        "len(motif)\n",
        "\n",
        "\n",
        "\n",
        "# Function to convert   \n",
        "def listToString(s):  \n",
        "    # initialize an empty string \n",
        "    str1 = \" \" \n",
        "    # return string   \n",
        "    return (str1.join(s)) \n",
        "        \n",
        "\n",
        "    \n",
        "def insert_str(string, str_to_insert, index):\n",
        "    return string[:index] + str_to_insert + string[index:]\n",
        "\n",
        "sequences_char2 = sequences_char\n",
        "for i in range(len(sequences_char)):\n",
        "    s = sequences_char[i]\n",
        "    s = listToString(s)\n",
        "    s = ''.join(s.split())\n",
        "    num = random.randint(0, 200)\n",
        "    ss=insert_str(s, enhancer,num)\n",
        "    s=insert_str(s, motif,num)\n",
        "    sequences_str.append(s)\n",
        "    sequences_str2.append(ss)\n",
        "\n",
        "  \n",
        "\n",
        "def assign_bp_value(a):\n",
        "    if a == 'A':\n",
        "        return 0\n",
        "    elif a == 'T':\n",
        "        return 80\n",
        "    elif a == 'C':\n",
        "        return 170\n",
        "    elif a == 'G':\n",
        "        return 255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bf195AUJONEO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "e97fd7d3-5828-4958-9a2e-ae5f04caf4a7"
      },
      "source": [
        "print(len(sequences_str[0]))\n",
        "print(len(sequences_str2[0]))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "784\n",
            "784\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvckVT2CVpKZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fab10b8a-1cce-4ad5-9568-48f3790c03be"
      },
      "source": [
        "len(sequences_str)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2500"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 217
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPEMQ3QwONER",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def get_img(seq_str):\n",
        "    images = list()\n",
        "    \n",
        "    for i in range(2500):\n",
        "        temp = np.array(list(seq_str[i]))\n",
        "        temp = np.reshape(temp, (28,28))\n",
        "        conv = np.zeros_like(temp, dtype='uint8')\n",
        "\n",
        "        for j in range (28):\n",
        "            for k in range (28):\n",
        "                conv[j][k]=assign_bp_value(temp[j][k])\n",
        "        \n",
        "        images.append(conv)\n",
        "\n",
        "    return images"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g9K-Eig8Bdjw",
        "colab_type": "text"
      },
      "source": [
        "# Linearly Encoded DNA Sequences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aNRH7yX8ONET",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "images_motifs = get_img(sequences_str)\n",
        "images_enhancers = get_img(sequences_str2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4iBdcIInBoqG",
        "colab_type": "text"
      },
      "source": [
        "# COmbining the datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxV9r1u-ONEV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 986
        },
        "outputId": "21525f7b-6c61-421e-e13e-27b980538316"
      },
      "source": [
        "npa = np.concatenate((np.asarray(images_motifs, dtype=np.float32),np.asarray(images_enhancers, dtype=np.float32) ))\n",
        "print(npa[0].shape)\n",
        "print(npa[2000])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(28, 28)\n",
            "[[170. 255. 170. 170.  80.  80. 255.   0.  80.   0.   0. 255. 170.  80.\n",
            "   80. 170.  80.   0.  80.  80. 255. 170.   0.  80. 170.  80. 255. 255.]\n",
            " [  0. 255.   0. 255. 255.   0.  80.  80.  80.   0. 255.   0.   0. 255.\n",
            "  170.  80.   0.  80.  80. 255. 170.   0.  80. 170. 255.   0.  80. 170.]\n",
            " [255.   0.  80. 170. 255.   0.  80. 170. 255.   0.  80. 170. 170. 255.\n",
            "  170. 255.   0.   0.  80. 170.   0. 255. 255.   0.   0. 170. 170. 255.]\n",
            " [ 80. 255. 255.   0.  80. 255. 170.   0. 255.  80.  80. 255.  80.  80.\n",
            "   80. 255. 255. 255. 255. 170.   0. 170. 255.  80.   0.   0. 255. 170.]\n",
            " [ 80. 255.   0.   0.   0.  80. 255.   0.   0.  80. 255.   0. 255.  80.\n",
            "  170. 170. 255. 170.  80.  80.   0. 170.  80.  80. 170.  80.   0. 255.]\n",
            " [255.  80. 255. 255.  80.   0. 170.  80.   0.   0.   0.  80. 170.  80.\n",
            "  255.   0.   0. 170.  80. 255. 170.  80. 170.   0. 255. 255.   0.   0.]\n",
            " [170.  80.  80.  80.   0.   0.   0. 255. 170.   0.  80.   0. 255. 255.\n",
            "  255. 255. 255.  80.   0.  80.  80. 255. 170.  80.   0.   0.  80.   0.]\n",
            " [  0.   0. 170.  80.  80.   0.   0. 255. 170. 255. 170. 255. 255.   0.\n",
            "   80. 170.  80. 255.  80. 170. 170.   0.  80. 255. 255. 255. 170.   0.]\n",
            " [170.   0. 255.  80.   0. 255. 255. 255. 255. 170.  80.   0.   0. 170.\n",
            "   80.   0.   0. 255. 170.   0. 170.   0. 255.  80. 255. 170.  80. 170.]\n",
            " [170. 255. 170.  80.  80. 170.  80. 170.   0.  80. 170. 170.  80.   0.\n",
            "   80.  80.  80.  80. 170.  80.  80. 255. 170. 170.  80.   0. 255.  80.]\n",
            " [  0. 170.  80. 170.   0. 170. 170. 255.   0.  80.  80.   0. 255.   0.\n",
            "   80.   0. 255. 170.  80.  80. 170. 255. 255.  80. 170.  80.   0.   0.]\n",
            " [ 80. 255.  80.   0. 170.  80.   0. 170. 170.   0.  80. 255.  80.   0.\n",
            "    0. 255.   0. 255.  80.  80.  80. 170.  80. 255. 255.   0.   0.   0.]\n",
            " [255. 170. 170.   0.   0.  80.  80. 170.  80.  80. 255.   0. 170. 255.\n",
            "    0.  80. 255.  80. 170.  80. 170. 170. 170. 170. 255.  80. 255. 170.]\n",
            " [  0.  80.   0.   0. 170. 170. 170.  80.   0.   0. 255.  80.   0.  80.\n",
            "   80. 170. 170. 170.  80. 255. 170.   0. 170. 170. 255.   0. 255. 255.]\n",
            " [170.   0.  80.  80.  80. 170. 170.  80. 255. 170.   0.   0. 170. 170.\n",
            "   80. 170. 255.  80.   0. 255. 255. 255. 170.   0.  80. 255. 170.  80.]\n",
            " [  0.   0.  80.  80.  80. 255. 255. 170.  80. 255. 170. 170.  80. 170.\n",
            "   80.   0. 255.  80.   0. 170.  80. 170. 170.  80. 255. 170. 170.  80.]\n",
            " [ 80. 255. 170.  80. 255.   0.   0. 255.   0.   0.   0. 255.   0. 170.\n",
            "    0.  80. 255. 255.   0. 170. 170. 255. 170.  80.  80. 170. 170.  80.]\n",
            " [ 80.  80. 170.   0.   0. 170.  80. 170.   0. 255. 255.  80.  80. 170.\n",
            "    0.   0. 255.  80. 170.  80. 255. 170.  80.   0. 255. 255. 170.  80.]\n",
            " [170.  80. 170.  80.   0.   0. 255. 170. 255. 170. 170.   0.   0. 255.\n",
            "    0. 170. 255. 255. 255.  80. 255. 255. 255. 255. 255.   0. 255. 255.]\n",
            " [255. 170.  80.   0.  80.  80. 170. 255.   0. 170. 170. 255. 255.  80.\n",
            "   80. 170. 255.  80.  80. 170. 255. 170.   0. 170. 170.  80.  80.  80.]\n",
            " [170. 170.  80. 255.   0. 255. 255.  80. 170. 170.   0.   0. 255. 170.\n",
            "  170.   0.  80. 170. 255.  80.  80. 255. 255. 255. 170.   0.  80.   0.]\n",
            " [  0.   0. 170.   0.   0.  80. 170. 255. 170.   0.  80. 255. 170. 170.\n",
            "   80. 170. 255. 255.   0.   0.   0.  80.  80.   0.  80. 170. 170. 170.]\n",
            " [  0.  80. 170. 170.   0.   0. 255. 170.  80.   0. 255. 170. 255. 170.\n",
            "    0.  80. 170.  80. 255.   0.  80. 170.  80. 170.   0. 170. 255. 170.]\n",
            " [170.   0.  80. 255. 170. 255.   0. 170. 255. 170.  80.  80.   0. 255.\n",
            "    0.  80.   0.  80. 170.   0. 170.   0. 255.  80.   0. 255.  80. 255.]\n",
            " [255. 255.   0. 170. 170. 170.  80. 255. 255.   0. 170. 170. 255. 255.\n",
            "   80. 255.   0.   0.  80. 170. 255.   0. 170. 170. 255.  80.   0. 255.]\n",
            " [255. 170. 255. 255. 255.  80. 255. 170.   0.   0.   0. 170.   0.   0.\n",
            "  170. 255.  80.   0.  80.   0.  80. 255. 170.  80.   0.  80.  80.   0.]\n",
            " [170. 170.   0.  80. 170. 255.  80.   0. 170.  80. 255. 170. 170.  80.\n",
            "    0. 170. 170.   0. 255.  80. 170.   0. 170. 255. 255.   0.  80.  80.]\n",
            " [170. 170.   0.  80. 170. 170.   0.  80.   0.  80.  80. 170.  80. 255.\n",
            "  170. 255. 170.   0. 170. 170.  80. 170. 255.   0.   0.   0.  80.  80.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BvNpm2b7Bvz9",
        "colab_type": "text"
      },
      "source": [
        "# CNN Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1GVTDhdONEY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "activation = 'relu'\n",
        "inp = tf.keras.Input(shape=(28,28,1))\n",
        "\n",
        "x = Conv2D(8, (3, 3), activation=activation)(inp)\n",
        "x = MaxPooling2D((2, 2))(x)\n",
        "x = Conv2D(16, (3, 3), activation=activation)(x)\n",
        "#x = MaxPooling2D((2, 2))(x)\n",
        "#x = BatchNormalization()(x)\n",
        "x = Conv2D(32, (3, 3), activation=activation)(x)\n",
        "#x = MaxPooling2D((2, 2))(x)\n",
        "x = Flatten()(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(32, activation=activation)(x)\n",
        "out = Dense(1, activation='sigmoid')(x)\n",
        "model = keras.Model(inp, out)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6IRoPKbXONEb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "8de2b4c7-432a-461d-99b0-65cbef5b83fb"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_63\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_32 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
            "_________________________________________________________________\n",
            "conv2d_76 (Conv2D)           (None, 26, 26, 8)         80        \n",
            "_________________________________________________________________\n",
            "max_pooling2d_53 (MaxPooling (None, 13, 13, 8)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_77 (Conv2D)           (None, 11, 11, 16)        1168      \n",
            "_________________________________________________________________\n",
            "conv2d_78 (Conv2D)           (None, 9, 9, 32)          4640      \n",
            "_________________________________________________________________\n",
            "flatten_31 (Flatten)         (None, 2592)              0         \n",
            "_________________________________________________________________\n",
            "dropout_29 (Dropout)         (None, 2592)              0         \n",
            "_________________________________________________________________\n",
            "dense_62 (Dense)             (None, 32)                82976     \n",
            "_________________________________________________________________\n",
            "dense_63 (Dense)             (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 88,897\n",
            "Trainable params: 88,897\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5nA2x6MbONEd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUfT_6_BONEf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels = np.concatenate((np.ones(2500), np.zeros(2500)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUlzx-rWONEh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label=labels.reshape(5000,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVER1tD0ONEk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4c1bf888-9be2-4ebf-c690-ba5070940d1b"
      },
      "source": [
        "npa.shape, label.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((5000, 28, 28), (5000, 1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 239
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_9h0DNHONEm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a072b160-865d-4450-e652-4c32e25add3f"
      },
      "source": [
        "optimizer = keras.optimizers.Adam(lr=0.0001)\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.fit(npa, label,epochs=100, batch_size=8, validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "500/500 [==============================] - 2s 3ms/step - loss: 3.7746 - accuracy: 0.5360 - val_loss: 0.7936 - val_accuracy: 0.4420\n",
            "Epoch 2/100\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.7532 - accuracy: 0.5817 - val_loss: 0.8349 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/100\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.6822 - accuracy: 0.6210 - val_loss: 0.9227 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/100\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.6706 - accuracy: 0.6240 - val_loss: 0.9362 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/100\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.6635 - accuracy: 0.6242 - val_loss: 1.0594 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/100\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.6636 - accuracy: 0.6240 - val_loss: 0.9757 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/100\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.6601 - accuracy: 0.6248 - val_loss: 0.8829 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/100\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.6558 - accuracy: 0.6250 - val_loss: 1.0725 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/100\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.6533 - accuracy: 0.6258 - val_loss: 1.1044 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/100\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.6494 - accuracy: 0.6248 - val_loss: 1.0162 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/100\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.6367 - accuracy: 0.6292 - val_loss: 1.0536 - val_accuracy: 0.0020\n",
            "Epoch 12/100\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.6193 - accuracy: 0.6505 - val_loss: 1.0872 - val_accuracy: 0.0330\n",
            "Epoch 13/100\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.5901 - accuracy: 0.6920 - val_loss: 0.9754 - val_accuracy: 0.2230\n",
            "Epoch 14/100\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.5582 - accuracy: 0.7255 - val_loss: 0.8043 - val_accuracy: 0.6270\n",
            "Epoch 15/100\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.5256 - accuracy: 0.7717 - val_loss: 0.8840 - val_accuracy: 0.5820\n",
            "Epoch 16/100\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.5050 - accuracy: 0.7952 - val_loss: 0.7867 - val_accuracy: 0.7660\n",
            "Epoch 17/100\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.4849 - accuracy: 0.8192 - val_loss: 0.8888 - val_accuracy: 0.6420\n",
            "Epoch 18/100\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.4453 - accuracy: 0.8267 - val_loss: 0.5043 - val_accuracy: 0.8150\n",
            "Epoch 19/100\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.3713 - accuracy: 0.8480 - val_loss: 0.5084 - val_accuracy: 0.7880\n",
            "Epoch 20/100\n",
            "500/500 [==============================] - 2s 3ms/step - loss: 0.3040 - accuracy: 0.8813 - val_loss: 0.5362 - val_accuracy: 0.7820\n",
            "Epoch 21/100\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.2680 - accuracy: 0.9040 - val_loss: 0.4236 - val_accuracy: 0.8380\n",
            "Epoch 22/100\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.2332 - accuracy: 0.9170 - val_loss: 0.3370 - val_accuracy: 0.8790\n",
            "Epoch 23/100\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.2071 - accuracy: 0.9310 - val_loss: 0.3865 - val_accuracy: 0.8730\n",
            "Epoch 24/100\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.1859 - accuracy: 0.9383 - val_loss: 0.3240 - val_accuracy: 0.8990\n",
            "Epoch 25/100\n",
            "500/500 [==============================] - 2s 3ms/step - loss: 0.1748 - accuracy: 0.9455 - val_loss: 0.3424 - val_accuracy: 0.8950\n",
            "Epoch 26/100\n",
            "500/500 [==============================] - 2s 3ms/step - loss: 0.1612 - accuracy: 0.9503 - val_loss: 0.2660 - val_accuracy: 0.9140\n",
            "Epoch 27/100\n",
            "500/500 [==============================] - 2s 3ms/step - loss: 0.1505 - accuracy: 0.9520 - val_loss: 0.3702 - val_accuracy: 0.8890\n",
            "Epoch 28/100\n",
            "500/500 [==============================] - 2s 3ms/step - loss: 0.1434 - accuracy: 0.9550 - val_loss: 0.2258 - val_accuracy: 0.9200\n",
            "Epoch 29/100\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.1364 - accuracy: 0.9540 - val_loss: 0.3063 - val_accuracy: 0.9080\n",
            "Epoch 30/100\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.1304 - accuracy: 0.9567 - val_loss: 0.2865 - val_accuracy: 0.9170\n",
            "Epoch 31/100\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.1235 - accuracy: 0.9553 - val_loss: 0.2219 - val_accuracy: 0.9210\n",
            "Epoch 32/100\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.1126 - accuracy: 0.9625 - val_loss: 0.1920 - val_accuracy: 0.9260\n",
            "Epoch 33/100\n",
            "500/500 [==============================] - 2s 3ms/step - loss: 0.1138 - accuracy: 0.9635 - val_loss: 0.2061 - val_accuracy: 0.9270\n",
            "Epoch 34/100\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.1078 - accuracy: 0.9622 - val_loss: 0.3127 - val_accuracy: 0.9110\n",
            "Epoch 35/100\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.0983 - accuracy: 0.9655 - val_loss: 0.2638 - val_accuracy: 0.9190\n",
            "Epoch 36/100\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.0965 - accuracy: 0.9645 - val_loss: 0.2976 - val_accuracy: 0.9160\n",
            "Epoch 37/100\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.0939 - accuracy: 0.9685 - val_loss: 0.2791 - val_accuracy: 0.9120\n",
            "Epoch 38/100\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.0916 - accuracy: 0.9663 - val_loss: 0.2611 - val_accuracy: 0.9240\n",
            "Epoch 39/100\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.0790 - accuracy: 0.9712 - val_loss: 0.2121 - val_accuracy: 0.9260\n",
            "Epoch 40/100\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.0886 - accuracy: 0.9668 - val_loss: 0.2343 - val_accuracy: 0.9260\n",
            "Epoch 41/100\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.0783 - accuracy: 0.9685 - val_loss: 0.2315 - val_accuracy: 0.9260\n",
            "Epoch 42/100\n",
            "500/500 [==============================] - 2s 3ms/step - loss: 0.0728 - accuracy: 0.9725 - val_loss: 0.2386 - val_accuracy: 0.9270\n",
            "Epoch 43/100\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.0689 - accuracy: 0.9747 - val_loss: 0.2272 - val_accuracy: 0.9280\n",
            "Epoch 44/100\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.0658 - accuracy: 0.9743 - val_loss: 0.3009 - val_accuracy: 0.9070\n",
            "Epoch 45/100\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.0620 - accuracy: 0.9747 - val_loss: 0.3558 - val_accuracy: 0.9160\n",
            "Epoch 46/100\n",
            "500/500 [==============================] - 2s 3ms/step - loss: 0.0625 - accuracy: 0.9760 - val_loss: 0.2513 - val_accuracy: 0.9260\n",
            "Epoch 47/100\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.0607 - accuracy: 0.9760 - val_loss: 0.3251 - val_accuracy: 0.9130\n",
            "Epoch 48/100\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.0590 - accuracy: 0.9745 - val_loss: 0.2830 - val_accuracy: 0.9220\n",
            "Epoch 49/100\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.0512 - accuracy: 0.9837 - val_loss: 0.2679 - val_accuracy: 0.9270\n",
            "Epoch 50/100\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.0594 - accuracy: 0.9778 - val_loss: 0.3124 - val_accuracy: 0.9190\n",
            "Epoch 51/100\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.0502 - accuracy: 0.9822 - val_loss: 0.2301 - val_accuracy: 0.9350\n",
            "Epoch 52/100\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.0557 - accuracy: 0.9797 - val_loss: 0.2873 - val_accuracy: 0.9240\n",
            "Epoch 53/100\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.0482 - accuracy: 0.9800 - val_loss: 0.3261 - val_accuracy: 0.9160\n",
            "Epoch 54/100\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.0444 - accuracy: 0.9815 - val_loss: 0.3267 - val_accuracy: 0.9220\n",
            "Epoch 55/100\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.0485 - accuracy: 0.9808 - val_loss: 0.3443 - val_accuracy: 0.9180\n",
            "Epoch 56/100\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.0430 - accuracy: 0.9850 - val_loss: 0.2892 - val_accuracy: 0.9260\n",
            "Epoch 57/100\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.0432 - accuracy: 0.9825 - val_loss: 0.2851 - val_accuracy: 0.9250\n",
            "Epoch 58/100\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.0438 - accuracy: 0.9827 - val_loss: 0.3263 - val_accuracy: 0.9220\n",
            "Epoch 59/100\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.0429 - accuracy: 0.9822 - val_loss: 0.3812 - val_accuracy: 0.9070\n",
            "Epoch 60/100\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.0343 - accuracy: 0.9875 - val_loss: 0.2561 - val_accuracy: 0.9330\n",
            "Epoch 61/100\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.0377 - accuracy: 0.9847 - val_loss: 0.3351 - val_accuracy: 0.9280\n",
            "Epoch 62/100\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.0434 - accuracy: 0.9837 - val_loss: 0.3077 - val_accuracy: 0.9270\n",
            "Epoch 63/100\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.0338 - accuracy: 0.9877 - val_loss: 0.3042 - val_accuracy: 0.9240\n",
            "Epoch 64/100\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.0333 - accuracy: 0.9855 - val_loss: 0.3573 - val_accuracy: 0.9240\n",
            "Epoch 65/100\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.0377 - accuracy: 0.9872 - val_loss: 0.2137 - val_accuracy: 0.9390\n",
            "Epoch 66/100\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.0357 - accuracy: 0.9845 - val_loss: 0.2574 - val_accuracy: 0.9380\n",
            "Epoch 67/100\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.0352 - accuracy: 0.9860 - val_loss: 0.2739 - val_accuracy: 0.9360\n",
            "Epoch 68/100\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.0376 - accuracy: 0.9868 - val_loss: 0.3368 - val_accuracy: 0.9260\n",
            "Epoch 69/100\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.0344 - accuracy: 0.9862 - val_loss: 0.2924 - val_accuracy: 0.9330\n",
            "Epoch 70/100\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.0312 - accuracy: 0.9877 - val_loss: 0.2663 - val_accuracy: 0.9340\n",
            "Epoch 71/100\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.0314 - accuracy: 0.9872 - val_loss: 0.2209 - val_accuracy: 0.9450\n",
            "Epoch 72/100\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.0274 - accuracy: 0.9895 - val_loss: 0.2602 - val_accuracy: 0.9300\n",
            "Epoch 73/100\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.0293 - accuracy: 0.9910 - val_loss: 0.3567 - val_accuracy: 0.9270\n",
            "Epoch 74/100\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.0274 - accuracy: 0.9905 - val_loss: 0.3062 - val_accuracy: 0.9310\n",
            "Epoch 75/100\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.0238 - accuracy: 0.9902 - val_loss: 0.3738 - val_accuracy: 0.9300\n",
            "Epoch 76/100\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.0264 - accuracy: 0.9910 - val_loss: 0.3322 - val_accuracy: 0.9280\n",
            "Epoch 77/100\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.0282 - accuracy: 0.9895 - val_loss: 0.2528 - val_accuracy: 0.9380\n",
            "Epoch 78/100\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.0266 - accuracy: 0.9902 - val_loss: 0.3408 - val_accuracy: 0.9300\n",
            "Epoch 79/100\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.0324 - accuracy: 0.9883 - val_loss: 0.2296 - val_accuracy: 0.9380\n",
            "Epoch 80/100\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.0278 - accuracy: 0.9905 - val_loss: 0.3042 - val_accuracy: 0.9310\n",
            "Epoch 81/100\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.0279 - accuracy: 0.9902 - val_loss: 0.3019 - val_accuracy: 0.9300\n",
            "Epoch 82/100\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.0206 - accuracy: 0.9918 - val_loss: 0.3593 - val_accuracy: 0.9320\n",
            "Epoch 83/100\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.0206 - accuracy: 0.9925 - val_loss: 0.3247 - val_accuracy: 0.9300\n",
            "Epoch 84/100\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.0232 - accuracy: 0.9912 - val_loss: 0.3056 - val_accuracy: 0.9340\n",
            "Epoch 85/100\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.0180 - accuracy: 0.9930 - val_loss: 0.3567 - val_accuracy: 0.9300\n",
            "Epoch 86/100\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.0264 - accuracy: 0.9900 - val_loss: 0.3252 - val_accuracy: 0.9350\n",
            "Epoch 87/100\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.0257 - accuracy: 0.9915 - val_loss: 0.3451 - val_accuracy: 0.9280\n",
            "Epoch 88/100\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.0209 - accuracy: 0.9925 - val_loss: 0.3941 - val_accuracy: 0.9280\n",
            "Epoch 89/100\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.0239 - accuracy: 0.9912 - val_loss: 0.1991 - val_accuracy: 0.9480\n",
            "Epoch 90/100\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.0229 - accuracy: 0.9923 - val_loss: 0.3437 - val_accuracy: 0.9320\n",
            "Epoch 91/100\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.0216 - accuracy: 0.9927 - val_loss: 0.3974 - val_accuracy: 0.9310\n",
            "Epoch 92/100\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.0227 - accuracy: 0.9908 - val_loss: 0.3535 - val_accuracy: 0.9250\n",
            "Epoch 93/100\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.0221 - accuracy: 0.9910 - val_loss: 0.3360 - val_accuracy: 0.9380\n",
            "Epoch 94/100\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.0204 - accuracy: 0.9925 - val_loss: 0.3555 - val_accuracy: 0.9380\n",
            "Epoch 95/100\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.0199 - accuracy: 0.9915 - val_loss: 0.3039 - val_accuracy: 0.9380\n",
            "Epoch 96/100\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.0196 - accuracy: 0.9935 - val_loss: 0.2516 - val_accuracy: 0.9390\n",
            "Epoch 97/100\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.0189 - accuracy: 0.9927 - val_loss: 0.3314 - val_accuracy: 0.9370\n",
            "Epoch 98/100\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.0174 - accuracy: 0.9937 - val_loss: 0.3723 - val_accuracy: 0.9370\n",
            "Epoch 99/100\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.0182 - accuracy: 0.9933 - val_loss: 0.5368 - val_accuracy: 0.9110\n",
            "Epoch 100/100\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.0261 - accuracy: 0.9915 - val_loss: 0.2706 - val_accuracy: 0.9390\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f5e3ecee5f8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 240
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTjnHcHPONEr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "convlayer = model.layers[4]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nxr1JWk0ONEu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5a369cad-fa25-4419-ffd1-5afea4ce71a7"
      },
      "source": [
        "print(convlayer)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f5e3ed95ef0>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQuVka8bONEv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "e3fa9843-4999-407e-bdeb-ddd7a5f499f9"
      },
      "source": [
        "weights = convlayer.get_weights()[0].squeeze()\n",
        "print(weights[:,:,0,0])\n",
        "#print('Convolution parameter shape: {}'.format(weights))\n",
        "#print(weights)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0.20610796  0.18492539  0.19780642]\n",
            " [ 0.03051323 -0.04284444 -0.01526043]\n",
            " [-0.01570004  0.02837513  0.04252924]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vE7Jng6HH_DH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "c24e8c08-366e-4634-da95-6c6ee2510ff5"
      },
      "source": [
        "a = weights[:,:,4,1]\n",
        "np.interp(a, (a.min(), a.max()), (0, 255))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 81.98358717, 169.00018938, 103.90513744],\n",
              "       [100.00406933,   0.        ,  85.21959786],\n",
              "       [ 43.81372951, 255.        , 154.22730698]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 244
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bLErPTphNKyy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "72210dac-7229-45f3-a165-17a1cdf0d132"
      },
      "source": [
        "a = weights\n",
        "b = np.interp(a, (a.min(), a.max()), (0, 255))\n",
        "print(np.count_nonzero(b < 65))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "644\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Z_T-xGVOJu-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "53521973-1889-4e3a-e69d-ee5464ac83d3"
      },
      "source": [
        "print (b.shape)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3, 3, 16, 32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oiPHBIORPVER",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0214523b-69e3-477b-c78c-757bda114125"
      },
      "source": [
        "3*3*16*32\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4608"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 233
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRK3iAdhPYnN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c0f4fedd-95a6-4877-83ce-0c122bc3defc"
      },
      "source": [
        "800/4600\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.17391304347826086"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 211
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxUxvX-yPd29",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "activation = 'relu'\n",
        "inp = tf.keras.Input(shape=(28,28,1))\n",
        "\n",
        "x = Conv2D(32, (3, 3), activation=activation)(inp)\n",
        "x = MaxPooling2D((2, 2))(x)\n",
        "x = Conv2D(32, (3, 3), activation=activation)(x)\n",
        "x = MaxPooling2D((2, 2))(x)\n",
        "x = BatchNormalization()(x)\n",
        "#x = Conv2D(32, (3, 3), activation=activation)(x)\n",
        "#x = MaxPooling2D((2, 2))(x)\n",
        "x = Flatten()(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(32, activation=activation)(x)\n",
        "out = Dense(1, activation='sigmoid')(x)\n",
        "model = keras.Model(inp, out)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "activation = 'relu'\n",
        "inp = tf.keras.Input(shape=(28,28,1))\n",
        "\n",
        "x = Conv2D(8, (3, 3), activation=activation)(inp)\n",
        "x = MaxPooling2D((2, 2))(x)\n",
        "x = Conv2D(16, (3, 3), activation=activation)(x)\n",
        "x = MaxPooling2D((2, 2))(x)\n",
        "#x = BatchNormalization()(x)\n",
        "#x = Conv2D(32, (3, 3), activation=activation)(x)\n",
        "#x = MaxPooling2D((2, 2))(x)\n",
        "x = Flatten()(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(32, activation=activation)(x)\n",
        "out = Dense(1, activation='sigmoid')(x)\n",
        "model = keras.Model(inp, out)\n",
        "\n",
        "optimizer = keras.optimizers.Adam(lr=0.0001)\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.fit(npa, label,epochs=200, batch_size=8, validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}